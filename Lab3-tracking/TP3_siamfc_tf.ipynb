{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP3_siamfc-tf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2cbdV0K7zQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MAKE SURE TO RUN ON PYTHON 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOLTajX5-aon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/torrvision/siamfc-tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWv5oxAAAfI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install virtualenv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U-FUZOmAkaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!virtualenv --python=/usr/bin/python2.7 ve-tracking"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n3UBADKBIKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!source /content/ve-tracking/bin/activate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urWGvOj6B7OW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/siamfc-tf/\n",
        "%matplotlib notebook\n",
        "!sudo pip install matplotlib\n",
        "!sudo pip install scipy\n",
        "!sudo pip install tensorflow-gpu\n",
        "!sudo pip install numpy\n",
        "!sudo pip install Pillow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i5REfsbFhA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir pretrained data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nd8FyuvIAGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/siamfc-tf/pretrained/\n",
        "!wget https://bit.ly/cfnet_networks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm9oiODfItpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip cfnet_networks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKw68NwBfTKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/siamfc-tf/data/validation/\n",
        "!mkdir /content/siamfc-tf/data/validation/vot2013_david\n",
        "!mkdir /content/siamfc-tf/data/validation/vot2013_gymnastics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5sm9tz4WcVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/siamfc-tf/data/validation/\n",
        "!mkdir /content/siamfc-tf/data/validation/vot2013_juice \n",
        "!mkdir /content/siamfc-tf/data/validation/vot2013_bicycle\n",
        "!mkdir /content/siamfc-tf/data/validation/vot2013_david\n",
        "!mkdir /content/siamfc-tf/data/validation/vot2013_gymnastics\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Leak42PJzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading juice dataset\n",
        "%cd /content/siamfc-tf/data/validation/vot2013_juice/\n",
        "!wget https://data.votchallenge.net/sequences/a5979f5dc2714862b1295dc5c6f5e779d1d7c865b838e6c468773d72ced9b371d64cb80ceae3237177c591a323d885cee5b97f152ca73af96daacdb0a78effb6.zip\n",
        "!unzip a5979f5dc2714862b1295dc5c6f5e779d1d7c865b838e6c468773d72ced9b371d64cb80ceae3237177c591a323d885cee5b97f152ca73af96daacdb0a78effb6.zip\n",
        "!wget https://data.votchallenge.net/vot2013/dataset/juice.zip\n",
        "!unzip juice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXcMN7oZPVjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Donwloading bicycle dataset\n",
        "%cd /content/siamfc-tf/data/validation/vot2013_bicycle/\n",
        "!wget https://data.votchallenge.net/sequences/84b35f0d0e6a1e39eea057d2141542688a51b1bc17bce9c6bf582b9ea744d2b3d705bb2238661481f20edc68e303002977968ac12201a7c0a8c66c2e9ce963bd.zip\n",
        "!unzip 84b35f0d0e6a1e39eea057d2141542688a51b1bc17bce9c6bf582b9ea744d2b3d705bb2238661481f20edc68e303002977968ac12201a7c0a8c66c2e9ce963bd.zip\n",
        "!wget https://data.votchallenge.net/vot2013/dataset/bicycle.zip\n",
        "!unzip bicycle.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzbg-1H4G1Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading David dataset\n",
        "%cd /content/siamfc-tf/data/validation/vot2013_david/\n",
        "!wget https://data.votchallenge.net/sequences/0b55211166a515fef8a37153589f82ef9deca547810d7034f362b5f254599e0295a406d24db4975a8e78023d145ca936530d296a3fa83f1e574f62cfc7ffbe52.zip\n",
        "!unzip 0b55211166a515fef8a37153589f82ef9deca547810d7034f362b5f254599e0295a406d24db4975a8e78023d145ca936530d296a3fa83f1e574f62cfc7ffbe52.zip\n",
        "!wget https://data.votchallenge.net/vot2013/dataset/david.zip\n",
        "!unzip david.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NK4O1lmGxJEr",
        "colab": {}
      },
      "source": [
        "#Downloading gymnastics dataset\n",
        "%cd /content/siamfc-tf/data/validation/vot2013_gymnastics/\n",
        "!wget https://data.votchallenge.net/sequences/8490ac66eed4d46cccf6d203e9401ffc7684cb0f5ec79291cdf7eae3044dd86f9d2899ec4e0b9b579b7f71fba8b5c8238e793f6307548f452158ab98a28d5e82.zip\n",
        "!unzip 8490ac66eed4d46cccf6d203e9401ffc7684cb0f5ec79291cdf7eae3044dd86f9d2899ec4e0b9b579b7f71fba8b5c8238e793f6307548f452158ab98a28d5e82.zip\n",
        "!wget https://data.votchallenge.net/vot2013/dataset/gymnastics.zip\n",
        "!unzip gymnastics.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "48nnnhugm3ze",
        "colab": {}
      },
      "source": [
        "#Downgrade to tensorflow 1.4 for code compatibility\n",
        "!sudo pip2.7 uninstall tensorflow\n",
        "!sudo pip2.7 install tensorflow==1.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7p_iP5-VjWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/siamfc-tf/pretrained/networks/baseline-conv5_e55.mat /content/siamfc-tf/pretrained/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7vMs5myQsSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Execute this cell if you wish to see quantitative results only\n",
        "#Wait for the SiamFC network to process all of the images so that it may produce a final score for each dataset\n",
        "%cd /content/siamfc-tf/\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(u'matplotlib inline')\n",
        "!python2.7 /content/siamfc-tf/run_tracker_evaluation.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWXvn54iFv9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code for Visualization\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def show_frame(frame, bbox, fig_n):\n",
        "    fig = plt.figure(fig_n)\n",
        "    ax = fig.add_subplot(111)\n",
        "    r = patches.Rectangle((bbox[0],bbox[1]), bbox[2], bbox[3], linewidth=2, edgecolor='r', fill=False)\n",
        "    ax.imshow(np.uint8(frame))\n",
        "    ax.add_patch(r)\n",
        "    plt.ion()\n",
        "    plt.show()\n",
        "    plt.pause(0.001)\n",
        "    plt.clf()\n",
        "\n",
        "\n",
        "def show_crops(crops, fig_n):\n",
        "    fig = plt.figure(fig_n)\n",
        "    ax1 = fig.add_subplot(131)\n",
        "    ax2 = fig.add_subplot(132)\n",
        "    ax3 = fig.add_subplot(133)\n",
        "    ax1.imshow(np.uint8(crops[0,:,:,:]))\n",
        "    ax2.imshow(np.uint8(crops[1,:,:,:]))\n",
        "    ax3.imshow(np.uint8(crops[2,:,:,:]))\n",
        "    plt.ion()\n",
        "    plt.show()\n",
        "    plt.pause(0.001)\n",
        "\n",
        "\n",
        "def show_scores(scores, fig_n):\n",
        "    fig = plt.figure(fig_n)\n",
        "    ax1 = fig.add_subplot(131)\n",
        "    ax2 = fig.add_subplot(132)\n",
        "    ax3 = fig.add_subplot(133)\n",
        "    ax1.imshow(scores[0,:,:], interpolation='none', cmap='hot')\n",
        "    ax2.imshow(scores[1,:,:], interpolation='none', cmap='hot')\n",
        "    ax3.imshow(scores[2,:,:], interpolation='none', cmap='hot')\n",
        "    plt.ion()\n",
        "    plt.show()\n",
        "    plt.pause(0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQI4hMbsH1TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to show qualitative results\n",
        "#Turn on visualization in the run.json file found in /content/siamfc-tf/parameters/run.json\n",
        "from __future__ import division\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import src.siamese as siam\n",
        "from src.tracker import tracker\n",
        "from src.parse_arguments import parse_arguments\n",
        "from src.region_to_bbox import region_to_bbox\n",
        "\n",
        "def main():\n",
        "    # avoid printing TF debugging information\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "    # TODO: allow parameters from command line or leave everything in json files?\n",
        "    hp, evaluation, run, env, design = parse_arguments()\n",
        "    # Set size for use with tf.image.resize_images with align_corners=True.\n",
        "    # For example,\n",
        "    #   [1 4 7] =>   [1 2 3 4 5 6 7]    (length 3*(3-1)+1)\n",
        "    # instead of\n",
        "    # [1 4 7] => [1 1 2 3 4 5 6 7 7]  (length 3*3)\n",
        "    final_score_sz = hp.response_up * (design.score_sz - 1) + 1\n",
        "    # build TF graph once for all\n",
        "    filename, image, templates_z, scores = siam.build_tracking_graph(final_score_sz, design, env)\n",
        "\n",
        "    # iterate through all videos of evaluation.dataset\n",
        "    if evaluation.video == 'all':\n",
        "        dataset_folder = os.path.join(env.root_dataset, evaluation.dataset)\n",
        "        videos_list = [v for v in os.listdir(dataset_folder)]\n",
        "        videos_list.sort()\n",
        "        nv = np.size(videos_list)\n",
        "        speed = np.zeros(nv * evaluation.n_subseq)\n",
        "        precisions = np.zeros(nv * evaluation.n_subseq)\n",
        "        precisions_auc = np.zeros(nv * evaluation.n_subseq)\n",
        "        ious = np.zeros(nv * evaluation.n_subseq)\n",
        "        lengths = np.zeros(nv * evaluation.n_subseq)\n",
        "        for i in range(nv):\n",
        "            gt, frame_name_list, frame_sz, n_frames = _init_video(env, evaluation, videos_list[i])\n",
        "            starts = np.rint(np.linspace(0, n_frames - 1, evaluation.n_subseq + 1))\n",
        "            starts = starts[0:evaluation.n_subseq]\n",
        "            for j in range(evaluation.n_subseq):\n",
        "                start_frame = int(starts[j])\n",
        "                gt_ = gt[start_frame:, :]\n",
        "                frame_name_list_ = frame_name_list[start_frame:]\n",
        "                pos_x, pos_y, target_w, target_h = region_to_bbox(gt_[0])\n",
        "                idx = i * evaluation.n_subseq + j\n",
        "                bboxes, speed[idx] = tracker(hp, run, design, frame_name_list_, pos_x, pos_y,\n",
        "                                                                     target_w, target_h, final_score_sz, filename,\n",
        "                                                                     image, templates_z, scores, start_frame)\n",
        "                lengths[idx], precisions[idx], precisions_auc[idx], ious[idx] = _compile_results(gt_, bboxes, evaluation.dist_threshold)\n",
        "               \n",
        "                print str(i) + ' -- ' + videos_list[i] + \\\n",
        "                ' -- Precision: ' + \"%.2f\" % precisions[idx] + \\\n",
        "                ' -- Precisions AUC: ' + \"%.2f\" % precisions_auc[idx] + \\\n",
        "                ' -- IOU: ' + \"%.2f\" % ious[idx] + \\\n",
        "                ' -- Speed: ' + \"%.2f\" % speed[idx] + ' --'\n",
        "                \n",
        "                print\n",
        "\n",
        "        tot_frames = np.sum(lengths)\n",
        "        mean_precision = np.sum(precisions * lengths) / tot_frames\n",
        "        mean_precision_auc = np.sum(precisions_auc * lengths) / tot_frames\n",
        "        mean_iou = np.sum(ious * lengths) / tot_frames\n",
        "        mean_speed = np.sum(speed * lengths) / tot_frames\n",
        "        print '-- Overall stats (averaged per frame) on ' + str(nv) + ' videos (' + str(tot_frames) + ' frames) --'\n",
        "        print ' -- Precision ' + \"(%d px)\" % evaluation.dist_threshold + ': ' + \"%.2f\" % mean_precision +\\\n",
        "              ' -- Precisions AUC: ' + \"%.2f\" % mean_precision_auc +\\\n",
        "              ' -- IOU: ' + \"%.2f\" % mean_iou +\\\n",
        "              ' -- Speed: ' + \"%.2f\" % mean_speed + ' --'\n",
        "        print\n",
        "\n",
        "    else:\n",
        "        gt, frame_name_list, _, _ = _init_video(env, evaluation, evaluation.video)\n",
        "        pos_x, pos_y, target_w, target_h = region_to_bbox(gt[evaluation.start_frame])\n",
        "        bboxes, speed = tracker(hp, run, design, frame_name_list, pos_x, pos_y, target_w, target_h, final_score_sz,\n",
        "                                filename, image, templates_z, scores, evaluation.start_frame)\n",
        "        _, precision, precision_auc, iou = _compile_results(gt, bboxes, evaluation.dist_threshold)\n",
        "        print evaluation.video + \\\n",
        "              ' -- Precision ' + \"(%d px)\" % evaluation.dist_threshold + ': ' + \"%.2f\" % precision +\\\n",
        "              ' -- Precision AUC: ' + \"%.2f\" % precision_auc + \\\n",
        "              ' -- IOU: ' + \"%.2f\" % iou + \\\n",
        "              ' -- Speed: ' + \"%.2f\" % speed + ' --'\n",
        "        print\n",
        "\n",
        "\n",
        "def _compile_results(gt, bboxes, dist_threshold):\n",
        "    l = np.size(bboxes, 0)\n",
        "    gt4 = np.zeros((l, 4))\n",
        "    new_distances = np.zeros(l)\n",
        "    new_ious = np.zeros(l)\n",
        "    n_thresholds = 50\n",
        "    precisions_ths = np.zeros(n_thresholds)\n",
        "\n",
        "    for i in range(l):\n",
        "        gt4[i, :] = region_to_bbox(gt[i, :], center=False)\n",
        "        new_distances[i] = _compute_distance(bboxes[i, :], gt4[i, :])\n",
        "        new_ious[i] = _compute_iou(bboxes[i, :], gt4[i, :])\n",
        "\n",
        "    # what's the percentage of frame in which center displacement is inferior to given threshold? (OTB metric)\n",
        "    precision = sum(new_distances < dist_threshold)/np.size(new_distances) * 100\n",
        "\n",
        "    # find above result for many thresholds, then report the AUC\n",
        "    thresholds = np.linspace(0, 25, n_thresholds+1)\n",
        "    thresholds = thresholds[-n_thresholds:]\n",
        "    # reverse it so that higher values of precision goes at the beginning\n",
        "    thresholds = thresholds[::-1]\n",
        "    for i in range(n_thresholds):\n",
        "        precisions_ths[i] = sum(new_distances < thresholds[i])/np.size(new_distances)\n",
        "\n",
        "    # integrate over the thresholds\n",
        "    precision_auc = np.trapz(precisions_ths)    \n",
        "\n",
        "    # per frame averaged intersection over union (OTB metric)\n",
        "    iou = np.mean(new_ious) * 100\n",
        "\n",
        "    return l, precision, precision_auc, iou\n",
        "\n",
        "\n",
        "def _init_video(env, evaluation, video):\n",
        "    video_folder = os.path.join(env.root_dataset, evaluation.dataset, video)\n",
        "    frame_name_list = [f for f in os.listdir(video_folder) if f.endswith(\".jpg\")]\n",
        "    frame_name_list = [os.path.join(env.root_dataset, evaluation.dataset, video, '') + s for s in frame_name_list]\n",
        "    frame_name_list.sort()\n",
        "    with Image.open(frame_name_list[0]) as img:\n",
        "        frame_sz = np.asarray(img.size)\n",
        "        frame_sz[1], frame_sz[0] = frame_sz[0], frame_sz[1]\n",
        "\n",
        "    # read the initialization from ground truth\n",
        "    gt_file = os.path.join(video_folder, 'groundtruth.txt')\n",
        "    gt = np.genfromtxt(gt_file, delimiter=',')\n",
        "    n_frames = len(frame_name_list)\n",
        "    assert n_frames == len(gt), 'Number of frames and number of GT lines should be equal.'\n",
        "\n",
        "    return gt, frame_name_list, frame_sz, n_frames\n",
        "\n",
        "\n",
        "def _compute_distance(boxA, boxB):\n",
        "    a = np.array((boxA[0]+boxA[2]/2, boxA[1]+boxA[3]/2))\n",
        "    b = np.array((boxB[0]+boxB[2]/2, boxB[1]+boxB[3]/2))\n",
        "    dist = np.linalg.norm(a - b)\n",
        "\n",
        "    assert dist >= 0\n",
        "    assert dist != float('Inf')\n",
        "\n",
        "    return dist\n",
        "\n",
        "\n",
        "def _compute_iou(boxA, boxB):\n",
        "    # determine the (x, y)-coordinates of the intersection rectangle\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
        "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
        "\n",
        "    if xA < xB and yA < yB:\n",
        "        # compute the area of intersection rectangle\n",
        "        interArea = (xB - xA) * (yB - yA)\n",
        "        # compute the area of both the prediction and ground-truth\n",
        "        # rectangles\n",
        "        boxAArea = boxA[2] * boxA[3]\n",
        "        boxBArea = boxB[2] * boxB[3]\n",
        "        # compute the intersection over union by taking the intersection\n",
        "        # area and dividing it by the sum of prediction + ground-truth\n",
        "        # areas - the intersection area\n",
        "        iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "    else:\n",
        "        iou = 0\n",
        "\n",
        "    assert iou >= 0\n",
        "    assert iou <= 1.01\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(main())\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}