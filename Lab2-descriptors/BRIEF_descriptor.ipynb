{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> INF6804 Lab 2: BRIEF descriptor </h1>\n",
    "<br>\n",
    "<h3 align=\"center\"> Daniel Wang, Oumayma Messoussi </h3>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import data, io\n",
    "from skimage.feature import BRIEF, corner_peaks, corner_fast, match_descriptors, plot_matches\n",
    "import matplotlib.pyplot as plt\n",
    "from sgm import *\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRIEF descriptor on KITTI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/gabilodeau/INF6804/blob/master/Descripteur%20BRIEF.ipynb\n",
    "\n",
    "img1 = io.imread('KITTI/data_scene_flow/training/image_2/000000_10.png', as_gray= True)\n",
    "img2 = io.imread('KITTI/data_scene_flow/training/image_2/000000_11.png', as_gray= True)\n",
    "plt.imshow(img2, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# extracting key points\n",
    "\n",
    "kps1 = corner_peaks(corner_fast(img1), min_distance=5)\n",
    "kps2 = corner_peaks(corner_fast(img2), min_distance=5)\n",
    "\n",
    "# BRIEF descriptor\n",
    "\n",
    "extractor = BRIEF(descriptor_size=128, patch_size=5, mode='normal')\n",
    "\n",
    "extractor.extract(img1, kps1)\n",
    "descriptor1 = extractor.descriptors\n",
    "extractor.extract(img2, kps2)\n",
    "descriptor2 = extractor.descriptors\n",
    "\n",
    "# matching\n",
    "\n",
    "matches = match_descriptors(descriptor1, descriptor2, cross_check=True)\n",
    "\n",
    "# visualization\n",
    "\n",
    "fig = plt.figure(figsize=(36, 20)) \n",
    "ax0 = plt.subplot()\n",
    "plot_matches(ax0, img1, img2, kps1, kps2, matches)\n",
    "ax0.axis('off')\n",
    "ax0.set_title(\"Image1 vs. Image2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(descriptor1, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGM disparity estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/beaupreda/semi-global-matching\n",
    "\n",
    "def compute_costs(left, right, parameters, save_images):\n",
    "    \"\"\"\n",
    "    first step of the sgm algorithm\n",
    "    :param left: left descriptor.\n",
    "    :param right: right descriptor.\n",
    "    :param parameters: structure containing parameters of the algorithm.\n",
    "    :param save_images: whether to save census images or not.\n",
    "    :return: H x W x D array with the matching costs.\n",
    "    \"\"\"\n",
    "    \n",
    "    max_disparity=64\n",
    "    P1=5\n",
    "    P2=70\n",
    "    csize=(7, 7)\n",
    "    bsize=(3, 3)\n",
    "    \n",
    "    assert left.shape[0] == right.shape[0] and left.shape[1] == right.shape[1], 'left & right must have the same shape.'\n",
    "    assert parameters.max_disparity > 0, 'maximum disparity must be greater than 0.'\n",
    "\n",
    "    height = left.shape[0]\n",
    "    width = left.shape[1]\n",
    "    cheight = parameters.csize[0]\n",
    "    cwidth = parameters.csize[1]\n",
    "    y_offset = int(cheight / 2)\n",
    "    x_offset = int(cwidth / 2)\n",
    "    disparity = parameters.max_disparity\n",
    "\n",
    "    left_census_values = left\n",
    "    right_census_values = right\n",
    "\n",
    "    print('\\tComputing cost volumes...', end='')\n",
    "    sys.stdout.flush()\n",
    "    dawn = t.time()\n",
    "    left_cost_volume = np.zeros(shape=(height, width, disparity), dtype=np.uint32)\n",
    "    right_cost_volume = np.zeros(shape=(height, width, disparity), dtype=np.uint32)\n",
    "    lcensus = np.zeros(shape=(height, width), dtype=np.int64)\n",
    "    rcensus = np.zeros(shape=(height, width), dtype=np.int64)\n",
    "    for d in range(0, disparity):\n",
    "        rcensus[:, (x_offset + d):(width - x_offset)] = right_census_values[:, x_offset:(width - d - x_offset)]\n",
    "        left_xor = np.int64(np.bitwise_xor(np.int64(left_census_values), rcensus))\n",
    "        left_distance = np.zeros(shape=(height, width), dtype=np.uint32)\n",
    "        while not np.all(left_xor == 0):\n",
    "            tmp = left_xor - 1\n",
    "            mask = left_xor != 0\n",
    "            left_xor[mask] = np.bitwise_and(left_xor[mask], tmp[mask])\n",
    "            left_distance[mask] = left_distance[mask] + 1\n",
    "        left_cost_volume[:, :, d] = left_distance\n",
    "\n",
    "        lcensus[:, x_offset:(width - d - x_offset)] = left_census_values[:, (x_offset + d):(width - x_offset)]\n",
    "        right_xor = np.int64(np.bitwise_xor(np.int64(right_census_values), lcensus))\n",
    "        right_distance = np.zeros(shape=(height, width), dtype=np.uint32)\n",
    "        while not np.all(right_xor == 0):\n",
    "            tmp = right_xor - 1\n",
    "            mask = right_xor != 0\n",
    "            right_xor[mask] = np.bitwise_and(right_xor[mask], tmp[mask])\n",
    "            right_distance[mask] = right_distance[mask] + 1\n",
    "        right_cost_volume[:, :, d] = right_distance\n",
    "\n",
    "    dusk = t.time()\n",
    "    print('\\t(done in {:.2f}s)'.format(dusk - dawn))\n",
    "\n",
    "    return left_cost_volume, right_cost_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(disparity, gt, disp):\n",
    "    \"\"\"\n",
    "    computes the recall of the disparity map.\n",
    "    :param disparity: disparity image.\n",
    "    :param gt: path to ground-truth image.\n",
    "    :param args: program arguments.\n",
    "    :return: rate of correct predictions.\n",
    "    \"\"\"\n",
    "    gt = np.float32(cv2.imread(gt, cv2.IMREAD_GRAYSCALE))\n",
    "    gt = gt[1:gt.shape[0]-1, 1:gt.shape[1]-1]\n",
    "    gt = np.int16(gt / 255.0 * float(disp))\n",
    "    disparity = np.int16(np.float32(disparity) / 255.0 * float(disp))\n",
    "    correct = np.count_nonzero(np.abs(disparity - gt) <= 3)\n",
    "    return float(correct) / gt.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgm(descriptorL, descriptorR, basename, gt1, gt2):\n",
    "    \"\"\"\n",
    "    main function applying the semi-global matching algorithm.\n",
    "    :return: void.\n",
    "    \"\"\"\n",
    "\n",
    "    disparity = 64\n",
    "    save_images = False\n",
    "    evaluation = True\n",
    "    output_name = basename\n",
    "    left_gt_name = gt1\n",
    "    right_gt_name = gt2\n",
    "\n",
    "    dawn = t.time()\n",
    "\n",
    "    parameters = Parameters(max_disparity=disparity, P1=10, P2=120, csize=(7, 7), bsize=(3, 3))\n",
    "    paths = Paths()\n",
    "\n",
    "    print('\\nStarting cost computation...')\n",
    "    left_cost_volume, right_cost_volume = compute_costs(descriptorL, descriptorR, parameters, save_images)\n",
    "\n",
    "    print('\\nStarting left aggregation computation...')\n",
    "    left_aggregation_volume = aggregate_costs(left_cost_volume, parameters, paths)\n",
    "    print('\\nStarting right aggregation computation...')\n",
    "    right_aggregation_volume = aggregate_costs(right_cost_volume, parameters, paths)\n",
    "\n",
    "    print('\\nSelecting best disparities...')\n",
    "    left_disparity_map = np.uint8(normalize(select_disparity(left_aggregation_volume), parameters))\n",
    "    right_disparity_map = np.uint8(normalize(select_disparity(right_aggregation_volume), parameters))\n",
    "    if save_images:\n",
    "        cv2.imwrite('left_disp_map_no_post_processing.png', left_disparity_map)\n",
    "        cv2.imwrite('right_disp_map_no_post_processing.png', right_disparity_map)\n",
    "\n",
    "    print('\\nApplying median filter...')\n",
    "    left_disparity_map = cv2.medianBlur(left_disparity_map, parameters.bsize[0])\n",
    "    right_disparity_map = cv2.medianBlur(right_disparity_map, parameters.bsize[0])\n",
    "    cv2.imwrite(f'left_disp_{output_name}', left_disparity_map)\n",
    "    cv2.imwrite(f'right_disp_{output_name}', right_disparity_map)\n",
    "\n",
    "    if evaluation:\n",
    "        print('\\nEvaluating left disparity map...')\n",
    "        left_recall = get_recall(left_disparity_map, left_gt_name, disparity)\n",
    "        print('\\tRecall left= {:.2f}%'.format(left_recall * 100.0))\n",
    "        print('\\nEvaluating right disparity map...')\n",
    "        right_recall = get_recall(right_disparity_map, right_gt_name, disparity)\n",
    "        print('\\tRecall right= {:.2f}%'.format(right_recall * 100.0))\n",
    "\n",
    "    dusk = t.time()\n",
    "    print('\\nFin.')\n",
    "    print('\\nTotal execution time = {:.2f}s'.format(dusk - dawn))\n",
    "    \n",
    "    return left_disparity_map, right_disparity_map, left_recall, right_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462520, 8)\n",
      "(462520, 8)\n",
      "(373, 1240)\n",
      "computing disparity...\n",
      "\n",
      "Starting cost computation...\n",
      "\tComputing cost volumes...\t(done in 1.13s)\n",
      "\n",
      "Starting left aggregation computation...\n",
      "\tProcessing paths east and west...\t(done in 33.87s)\n",
      "\tProcessing paths south-east and north-west...\t(done in 78.13s)\n",
      "\tProcessing paths south and north...\t(done in 76.87s)\n",
      "\tProcessing paths south-west and north-east..."
     ]
    }
   ],
   "source": [
    "# Source: http://timosam.com/python_opencv_depthimage\n",
    "\n",
    "stereo = cv2.StereoSGBM_create(\n",
    "    minDisparity=0,\n",
    "    numDisparities=160,     \n",
    "    blockSize=1,\n",
    "    P1=8 * 3 * 3 ** 2,\n",
    "    P2=32 * 3 * 3 ** 2,\n",
    "    disp12MaxDiff=1,\n",
    "    uniquenessRatio=15,\n",
    "    speckleWindowSize=0,\n",
    "    speckleRange=2,\n",
    "    preFilterCap=63,\n",
    "    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    ")\n",
    "\n",
    "for image1, image2, gt1, gt2 in zip(glob.glob('KITTI/data_scene_flow/training/image_2/0000[1-2][0-9]_10.png'), \n",
    "                              glob.glob('KITTI/data_scene_flow/training/image_2/0000[1-2][0-9]_11.png'),\n",
    "                              glob.glob('KITTI/data_scene_flow/training/disp_noc_0/0000[1-2][0-9]_10.png'),\n",
    "                              glob.glob('KITTI/data_scene_flow/training/disp_noc_1/0000[1-2][0-9]_10.png')):\n",
    "    \n",
    "    imgL = cv2.imread(image1, cv2.IMREAD_GRAYSCALE)\n",
    "    imgR = cv2.imread(image2, cv2.IMREAD_GRAYSCALE)\n",
    "    gtL = cv2.imread(gt1, cv2.IMREAD_GRAYSCALE)\n",
    "    gtR = cv2.imread(gt2, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # matrix indices to use as \"key points\"\n",
    "\n",
    "    indicesL = np.zeros(((imgL.shape[0]-2)*(imgL.shape[1]-2), 2), dtype=np.int64)\n",
    "    indicesR = np.zeros(((imgR.shape[0]-2)*(imgR.shape[1]-2), 2), dtype=np.int64)\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(1, imgL.shape[0]-1):\n",
    "        for j in range(1, imgL.shape[1]-1):\n",
    "            indicesL[k][0], indicesL[k][1] = i, j\n",
    "            k += 1\n",
    "    k = 0\n",
    "    for i in range(1, imgR.shape[0]-1):\n",
    "        for j in range(1, imgR.shape[1]-1):      \n",
    "            indicesR[k][0], indicesR[k][1] = i, j\n",
    "            k += 1\n",
    "\n",
    "    # BRIEF descriptor\n",
    "\n",
    "    extractor = BRIEF(descriptor_size=8, patch_size=3, mode='normal')\n",
    "    \n",
    "    extractor.extract(imgL, indicesL)\n",
    "    descriptorL = extractor.descriptors\n",
    "    extractor.extract(imgR, indicesR)\n",
    "    descriptorR = extractor.descriptors\n",
    "\n",
    "    print(descriptorL.shape)\n",
    "    \n",
    "    descL = np.ndarray((descriptorL.shape[0],1), dtype=np.int64)\n",
    "    descR = np.ndarray((descriptorR.shape[0],1), dtype=np.int64)\n",
    "\n",
    "    for i in range(descriptorL.shape[0]):\n",
    "        descriptorL[i, 0] = descriptorL[i].dot(2**np.arange(descriptorL[i].size)[::-1])\n",
    "        descL[i] = descriptorL[i].dot(2**np.arange(descriptorL[i].size)[::-1])\n",
    "        \n",
    "    for i in range(descriptorR.shape[0]):\n",
    "        descriptorR[i, 0] = descriptorR[i].dot(2**np.arange(descriptorR[i].size)[::-1])\n",
    "        descL[i] = descriptorL[i].dot(2**np.arange(descriptorL[i].size)[::-1])\n",
    "    \n",
    "    print(descriptorL.shape)\n",
    "    \n",
    "    descriptorL = descL.reshape((373, 1240))\n",
    "    descriptorR = descL.reshape((373, 1240))\n",
    "    \n",
    "    print(descriptorL.shape)\n",
    "\n",
    "    # SGM matching\n",
    "    \n",
    "    print('computing disparity...')\n",
    "    \n",
    "    left_disparity_map, right_disparity_map, left_recall, right_recall = sgm(descriptorL, descriptorR, image1.split('/')[3].split('\\\\')[1], gt1, gt2)\n",
    "    #disparity = stereo.compute(descriptorL.astype(np.uint8), descriptorR.astype(np.uint8)).astype(np.float32)/16\n",
    "    #disparity = cv2.normalize(src=disparity, dst=disparity, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "    \n",
    "    # visualization\n",
    "    \n",
    "#     fig = plt.figure(figsize=(200, 200))\n",
    "            \n",
    "#     x = fig.add_subplot(1,2, 1)\n",
    "#     x.set_title('imgL')\n",
    "#     plt.imshow(imgL, cmap='gray')\n",
    "\n",
    "#     y = fig.add_subplot(1,2, 2)\n",
    "#     y.set_title('imgR')\n",
    "#     plt.imshow(imgR, cmap='gray')\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(200, 200))\n",
    "    \n",
    "    x = fig.add_subplot(1,2, 1)\n",
    "    x.set_title('gt')\n",
    "    plt.imshow(gtL, cmap='gray')\n",
    "\n",
    "    y = fig.add_subplot(1,2, 2)\n",
    "    y.set_title('disparity')\n",
    "    plt.imshow(left_disparity_map, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'left_disparity_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-fb41fbb170dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_disparity_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'left_disparity_map' is not defined"
     ]
    }
   ],
   "source": [
    "np.max(left_disparity_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
